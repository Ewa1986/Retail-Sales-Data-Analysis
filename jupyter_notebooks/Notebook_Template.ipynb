{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(RETAIL SALES DATA ANALYSIS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Analyse retail sales data to identify trends, insights, and the impact of promotional markdowns on sales. \n",
        "\n",
        "* Provide comprehensive, visually appealing sales reports and insights to assist in strategic decision-making.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "*  Data from the Excel sheets (Stores, Features, Sales) downloaded from https://www.kaggle.com/datasets/manjeetsingh/retaildataset/data\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Retail-Sales-Data-Analysis'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retail_Sales\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"Retail_Sales\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
            "0      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
            "1      1  12/02/2010        38.51       2.548        NaN        NaN   \n",
            "2      1  19/02/2010        39.93       2.514        NaN        NaN   \n",
            "3      1  26/02/2010        46.63       2.561        NaN        NaN   \n",
            "4      1  05/03/2010        46.50       2.625        NaN        NaN   \n",
            "5      1  12/03/2010        57.79       2.667        NaN        NaN   \n",
            "6      1  19/03/2010        54.58       2.720        NaN        NaN   \n",
            "7      1  26/03/2010        51.45       2.732        NaN        NaN   \n",
            "8      1  02/04/2010        62.27       2.719        NaN        NaN   \n",
            "9      1  09/04/2010        65.86       2.770        NaN        NaN   \n",
            "\n",
            "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
            "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
            "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
            "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
            "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
            "4        NaN        NaN        NaN  211.350143         8.106      False  \n",
            "5        NaN        NaN        NaN  211.380643         8.106      False  \n",
            "6        NaN        NaN        NaN  211.215635         8.106      False  \n",
            "7        NaN        NaN        NaN  211.018042         8.106      False  \n",
            "8        NaN        NaN        NaN  210.820450         7.808      False  \n",
            "9        NaN        NaN        NaN  210.622857         7.808      False  \n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file into a Data Frame\n",
        "df_features = pd.read_csv(\"/workspace/Retail-Sales-Data-Analysis/jupyter_notebooks/Features_data_set.csv\")\n",
        "\n",
        "# Display the first 10 rows of the Data Frame\n",
        "print(df_features.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
            "0      1     1  05/02/2010      24924.50      False\n",
            "1      1     1  12/02/2010      46039.49       True\n",
            "2      1     1  19/02/2010      41595.55      False\n",
            "3      1     1  26/02/2010      19403.54      False\n",
            "4      1     1  05/03/2010      21827.90      False\n",
            "5      1     1  12/03/2010      21043.39      False\n",
            "6      1     1  19/03/2010      22136.64      False\n",
            "7      1     1  26/03/2010      26229.21      False\n",
            "8      1     1  02/04/2010      57258.43      False\n",
            "9      1     1  09/04/2010      42960.91      False\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file into a Data Frame\n",
        "df_sales = pd.read_csv(\"/workspace/Retail-Sales-Data-Analysis/jupyter_notebooks/sales_data_set.csv\")\n",
        "\n",
        "# Display the first 10 rows of the Data Frame\n",
        "print(df_sales.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Store Type    Size\n",
            "0      1    A  151315\n",
            "1      2    A  202307\n",
            "2      3    B   37392\n",
            "3      4    A  205863\n",
            "4      5    B   34875\n",
            "5      6    A  202505\n",
            "6      7    B   70713\n",
            "7      8    A  155078\n",
            "8      9    B  125833\n",
            "9     10    B  126512\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file into a Data Frame\n",
        "df_stores = pd.read_csv(\"/workspace/Retail-Sales-Data-Analysis/jupyter_notebooks/stores_data_set.csv\")\n",
        "\n",
        "# Display the first 10 rows of the Data Frame\n",
        "print(df_stores.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Store         5 non-null      int64  \n",
            " 1   Dept          5 non-null      int64  \n",
            " 2   Date          5 non-null      object \n",
            " 3   Weekly_Sales  5 non-null      float64\n",
            " 4   IsHoliday     5 non-null      bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(1)\n",
            "memory usage: 293.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "df_sales.head().info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45 entries, 0 to 44\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Store   45 non-null     int64 \n",
            " 1   Type    45 non-null     object\n",
            " 2   Size    45 non-null     int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df_stores.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8190 entries, 0 to 8189\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Store         8190 non-null   int64  \n",
            " 1   Date          8190 non-null   object \n",
            " 2   Temperature   8190 non-null   float64\n",
            " 3   Fuel_Price    8190 non-null   float64\n",
            " 4   MarkDown1     4032 non-null   float64\n",
            " 5   MarkDown2     2921 non-null   float64\n",
            " 6   MarkDown3     3613 non-null   float64\n",
            " 7   MarkDown4     3464 non-null   float64\n",
            " 8   MarkDown5     4050 non-null   float64\n",
            " 9   CPI           7605 non-null   float64\n",
            " 10  Unemployment  7605 non-null   float64\n",
            " 11  IsHoliday     8190 non-null   bool   \n",
            "dtypes: bool(1), float64(9), int64(1), object(1)\n",
            "memory usage: 712.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df_features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_features['Date'] = pd.to_datetime(df_features['Date'],dayfirst=True)\n",
        "df_sales['Date'] = pd.to_datetime(df_sales['Date'],dayfirst=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merging df_sales with df_features\n",
        "\n",
        "df_sales_features = pd.merge(df_sales, df_features, on=['Store', 'Date'], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Store                0\n",
              "Dept                 0\n",
              "Date                 0\n",
              "Weekly_Sales         0\n",
              "IsHoliday_x          0\n",
              "Temperature          0\n",
              "Fuel_Price           0\n",
              "MarkDown1       270889\n",
              "MarkDown2       310322\n",
              "MarkDown3       284479\n",
              "MarkDown4       286603\n",
              "MarkDown5       270138\n",
              "CPI                  0\n",
              "Unemployment         0\n",
              "IsHoliday_y          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking df_sales_features for null values\n",
        "\n",
        "df_sales_features.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Store    0\n",
              "Type     0\n",
              "Size     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking df_stores for null values\n",
        "\n",
        "df_stores.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block (553063055.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
